{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import Audio\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to MIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Discrete Fourier Transform and friends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sine(frequency, a=1, dur=1, sr=22050):\n",
    "    \"\"\"\n",
    "    creates a sine wave\n",
    "    \n",
    "    Args:\n",
    "        frequency (int): number of cycles per second (Hz)\n",
    "        a (int): amplitude of signal\n",
    "        dur (int): duration of signal in seconds\n",
    "        sr (int): samplerate of signal        \n",
    "    \"\"\"\n",
    "    return a*np.sin(np.arange(dur*sr) / sr * 2 * np.pi * frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 22050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = create_sine(1, dur=5)\n",
    "plt.plot(sig);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(data=sig, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hmmm, why isn't this working? Let's try with a different frequency..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = create_sine(440, dur=5)\n",
    "plt.plot(sig);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(data=sig, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dft(sig, win_len=1024):\n",
    "    window = np.hamming(win_len)\n",
    "    sig = window * sig[:win_len]\n",
    "    D = np.abs(np.fft.fft(sig))[:win_len//2]\n",
    "    xs = np.arange(win_len/2) * (22050/win_len)\n",
    "    plt.plot(xs, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dft(sig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, let's build a more complex signal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = create_sine(440) + create_sine(1760, a=0.6)\n",
    "Audio(data=sig, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dft(sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = 440\n",
    "sig = 0\n",
    "for i in [1, 2, 4, 6, 8, 10]:\n",
    "    sig += create_sine(f0*i)\n",
    "sig /= np.max(np.abs(sig))\n",
    "plot_dft(sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(data=sig, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok, let's let's try some music!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's look at some music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = librosa.util.example_audio_file()\n",
    "y, sr = librosa.core.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(data=y, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y[:sr]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.waveplot(y, sr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dft(y[sr*5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stft(sig):\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(sig)), ref=np.max)\n",
    "    librosa.display.specshow(D, y_axis='linear');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stft(y[:sr*10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mel_specgtrogram(y):\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, fmax=8000)\n",
    "    S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "    librosa.display.specshow(S_dB, x_axis='time',\n",
    "                             y_axis='mel', sr=sr);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mel_specgtrogram(y[:sr*10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "phew! that's enough plotting for now, let's take a break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chroma features store pitch class information for each analysis frame. As you can see below, the predominant pitch in the test track is `E`, which along with prominent energy in `A` and `B` indicates this song is likely in the key of `E`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "librosa.display.specshow(chroma, y_axis='chroma', x_axis='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MFCCs (Mel Frequency Cepstral Coefficients) are a standard MIR feature that describe the spectral content (timbre) of audio. They are particularly useful for instrument classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccs = librosa.feature.mfcc(y=y, sr=sr)\n",
    "librosa.display.specshow(mfccs, x_axis='time');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use the two features described above (MFCCs and Chroma) to build a simple genre classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# point this to the root of the Tzanetakis genre dataset\n",
    "# http://marsyas.info/downloads/datasets.html\n",
    "GTZAN_ROOT = 'genres/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mfccs(y, sr):\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr)\n",
    "    return np.concatenate([\n",
    "        mfccs.mean(axis=1),\n",
    "        mfccs.std(axis=1)\n",
    "    ])\n",
    "\n",
    "def extract_chroma(y, sr):\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    return np.concatenate([\n",
    "        chroma.mean(axis=1),\n",
    "        chroma.std(axis=1)\n",
    "    ])\n",
    "\n",
    "def extract_feats(y, sr):\n",
    "    chroma = extract_chroma(y, sr)\n",
    "    mfccs = extract_mfccs(y, sr)\n",
    "    feats = np.concatenate([chroma, mfccs])\n",
    "    \n",
    "    labels = []   \n",
    "    for i in range(len(chroma) // 2):\n",
    "        labels.append('chroma_{}_mean'.format(i))\n",
    "    for i in range(len(chroma) // 2):\n",
    "        labels.append('chroma_{}_std'.format(i))\n",
    "    for i in range(len(mfccs) // 2):\n",
    "        labels.append('mfcc_{}_mean'.format(i))\n",
    "    for i in range(len(mfccs) // 2):\n",
    "        labels.append('mfcc_{}_std'.format(i))\n",
    "        \n",
    "    return feats, labels\n",
    "\n",
    "def feats_for_fname(fname):\n",
    "    y, sr = librosa.core.load(fname)\n",
    "    return extract_feats(y, sr)\n",
    "\n",
    "def fname_generator(genre, gtzan_root=GTZAN_ROOT):\n",
    "    for root, dirs, files in os.walk(gtzan_root):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav') and genre in file:\n",
    "                yield os.path.join(root, file)         \n",
    "                \n",
    "def df_for_genre(genre):\n",
    "    fnames = []\n",
    "    feats = []\n",
    "    for fname in fname_generator(genre):\n",
    "        # print(\"extracting feats for {}\".format(fname))\n",
    "        cur_feats, labels = feats_for_fname(fname)\n",
    "        fnames.append(fname)\n",
    "        feats.append(cur_feats)\n",
    "    df = pd.DataFrame(feats, columns=labels, index=fnames)\n",
    "    df['label'] = genre\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by writing a few helper functions that will allow us to scan a subdirectory of our dataset, load audio files matching a specific genre, extract features from these audio files, and combine the resulting data into a Pandas DataFrame.\n",
    "\n",
    "Below, we load features for two musical genres, `pop` and `classical`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([df_for_genre(genre) for genre in ['pop', 'classical']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now split the data into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['label']\n",
    "X = data.drop('label', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we build a classification pipeline using two components: a `StandardScaler` which will z-normalize our data, and a `RandomForestClassifier` using the default parameterization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(StandardScaler(), RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can train the model, predict the genres of our test set, and check our accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not too bad!"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
